{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fraud detection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOu1ZHfIWfaCMIB6rZ0sIqJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alefefreire/MLtraining/blob/master/Fraud_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWGEfzikgudg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "5501c688-797d-496d-a409-c6c7ec40f88c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw7-f22Kg4ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import mode, gaussian_kde\n",
        "from scipy.optimize import minimize, shgo\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.model_selection import KFold,StratifiedKFold\n",
        "from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score,fbeta_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_context(\"paper\", font_scale=2)\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "path=r'/content/drive/My Drive/Data/'\n",
        "\n",
        "df=pd.read_csv(path+'bank-full.csv',sep=';')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR-tCKiBj4R4",
        "colab_type": "text"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVZh0l4pj8mR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rrmse(y_true,y_pred):\n",
        "    return np.sqrt(mse(y_true,y_pred))/np.mean(y_true)\n",
        "\n",
        "def split_df(data,ids,val_size,id_col,shuffle=True):\n",
        "    if shuffle: rn.shuffle(camps)\n",
        "\n",
        "    length = len(ids)\n",
        "\n",
        "    split = int(val_size * length)\n",
        "\n",
        "    idx_val = ids[-split:]\n",
        "    idx_tr = ids[:-split]\n",
        "    \n",
        "    return data[data[id_col].isin(idx_tr)],data[data[id_col].isin(idx_val)]\n",
        "\n",
        "def cross_valid(model,x,folds,metric,verbose=True):\n",
        "    \"\"\" \n",
        "    This function does cross validation for general regressors. \n",
        "        model: Sklearn model or customized model with fit and predict methods;\n",
        "        x : Data as a numpy matrix containg with ***the last column as target***;\n",
        "        folds: Number of folds;\n",
        "        metrics : 'mae': mse,'rmse','rrmse'\n",
        "        verbose: Flag to print report over iterations;\n",
        "        \n",
        "    returns: List with scores over the folders\n",
        "    \"\"\"    \n",
        "\n",
        "    score=[]\n",
        "    \n",
        "\n",
        "    kf = KFold(folds,shuffle=False,random_state=0) \n",
        "\n",
        "\n",
        "    i=0\n",
        "    for train_index, test_index in kf.split(x):\n",
        "\n",
        "        xtrain = x[train_index,:]\n",
        "        xtest = x[test_index,:]\n",
        "\n",
        "        model.fit(xtrain[:,:-1],xtrain[:,-1])\n",
        "\n",
        "        ypred = model.predict(xtest[:,:-1])\n",
        "\n",
        "        ytrue= xtest[:,-1] \n",
        "          \n",
        "              \n",
        "        if metric == 'mae':\n",
        "            score.append(mae(ytrue,ypred))\n",
        "        elif metric == 'mse':\n",
        "            score.append(mse(ytrue,ypred))\n",
        "        elif metric == 'rrmse':\n",
        "            score.append(rrmse(ytrue,ypred))\n",
        "\n",
        "        else:\n",
        "            score.append(rmse(xtest[:,-1],ypred))\n",
        "\n",
        "        if verbose:\n",
        "            print('-'*30)\n",
        "            print(f'\\nFold {i+1} out of {folds}')\n",
        "            print(f'{metric}: {score[i]}')\n",
        "\n",
        "        i+=1\n",
        "\n",
        "    if verbose:\n",
        "        print(f'\\n Overall Score:')\n",
        "        print(f'{metric}:    Mean: {np.mean(score)}   Std: {np.std(score)}')\n",
        "\n",
        "\n",
        "    return score\n",
        "def cross_valid_key(model,x,key,preds,target,metric,verbose=True):\n",
        "    \"\"\" \n",
        "    This function does cross validation for general regressors. \n",
        "        model: Sklearn model or customized model with fit and predict methods;\n",
        "        x : Data as a numpy matrix containg with ***the last column as target***;\n",
        "        key: Column name containing keys for spliting the folds;\n",
        "        metrics : 'mae': mse,'rmse','rrmse'\n",
        "        verbose: Flag to print report over iterations;\n",
        "        \n",
        "    returns: List with scores over the folders\n",
        "    \"\"\"    \n",
        "\n",
        "    score=[]\n",
        "    \n",
        "    keys = x[key].unique().tolist()\n",
        " \n",
        "\n",
        "\n",
        "    for idx, item in enumerate([1,2,3,4,5]):\n",
        "\n",
        "        xtrain,xtest = split_camp(x,keys,0.2)\n",
        "        \n",
        "        model.fit(xtrain[feat],xtrain[target])\n",
        "\n",
        "        ypred = model.predict(xtest[feat])\n",
        "        \n",
        "        ytrue= xtest[target].values \n",
        "          \n",
        "        if metric == 'mae':\n",
        "            score.append(mae(ytrue,ypred))\n",
        "        elif metric == 'mse':\n",
        "            score.append(mse(ytrue,ypred))\n",
        "        elif metric == 'rrmse':\n",
        "            score.append(rrmse(ytrue,ypred))\n",
        "\n",
        "        else:\n",
        "            score.append(rmse(xtest[target].tolist(),ypred))\n",
        "\n",
        "        if verbose:\n",
        "            print('-'*30)\n",
        "            print(f'\\nFold {idx} out of 5')\n",
        "            print(f'Key {item}')\n",
        "            print(f'{metric}: {score[idx]}')\n",
        "\n",
        " \n",
        "\n",
        "    if verbose:\n",
        "        print(f'\\n Overall Score:')\n",
        "        print(f'{metric}:    Mean: {np.mean(score)}   Std: {np.std(score)}')\n",
        "\n",
        "\n",
        "    return score\n",
        "\n",
        "def kde(array, cut_down=True, bw_method='scott'):\n",
        "    if cut_down:\n",
        "        bins, counts = np.unique(array, return_counts=True)\n",
        "        f_mean = counts.mean()\n",
        "        f_above_mean = bins[counts > f_mean]\n",
        "        bounds = [f_above_mean.min(), f_above_mean.max()]\n",
        "        array = array[np.bitwise_and(bounds[0] < array, array < bounds[1])]\n",
        "    return gaussian_kde(array, bw_method=bw_method)\n",
        "\n",
        "def mode_estimation(array, cut_down=True, bw_method='scott'):\n",
        "    kernel = kde(array, cut_down=cut_down, bw_method=bw_method)\n",
        "    bounds = np.array([[array.min(), array.max()]])\n",
        "    results = shgo(lambda x: -kernel(x)[0], bounds=bounds, n=100*len(array))\n",
        "    return results.x[0]\n",
        "\n",
        "def tsplot(y, lags=None, figsize=(10, 8), style='bmh'):\n",
        "    if not isinstance(y, pd.Series):\n",
        "        y = pd.Series(y)\n",
        "    \n",
        "    with plt.style.context(style):    \n",
        "        xticks = np.arange(0,lags)\n",
        "        fig = plt.figure(figsize=figsize)\n",
        "        #mpl.rcParams['font.family'] = 'Ubuntu Mono'\n",
        "        layout = (3, 2)\n",
        "        ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n",
        "        acf_ax = plt.subplot2grid(layout, (1, 0))\n",
        "        pacf_ax = plt.subplot2grid(layout, (1, 1))\n",
        "        qq_ax = plt.subplot2grid(layout, (2, 0))\n",
        "        pp_ax = plt.subplot2grid(layout, (2, 1))\n",
        "        \n",
        "        y.plot(ax=ts_ax)\n",
        "        ts_ax.set_title('Time Series Analysis Plots')\n",
        "        smt.graphics.plot_acf(y, lags=lags, ax=acf_ax, alpha=0.05)\n",
        "        smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax, alpha=0.05)\n",
        "        sm.qqplot(y, line='s', ax=qq_ax)\n",
        "        qq_ax.set_title('QQ Plot')        \n",
        "        scs.probplot(y, sparams=(y.mean(), y.std()), plot=pp_ax)\n",
        "\n",
        "        plt.tight_layout()\n",
        "    return\n",
        "\n",
        "# Adpated from https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/        \n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    \n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    var_n= data.columns.tolist()\n",
        "    df = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))                    \n",
        "        names += [(var_n[j]+'(t-%d)' % ( i)) for j in range(n_vars)]\n",
        " \n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "        cols.append(df.shift(-i))\n",
        "        if i == 0:\n",
        "            names += [(var_n[j]+'(t)') for j in range(n_vars)]\n",
        "        else:\n",
        "            names += [(var_n[j]+'(t+%d)' % (i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    \n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        " \n",
        "    return agg\n",
        " \n",
        " \n",
        "def dataTimeSeries(timesteps,df,predictors,target,dropnan,out=2,dropVars=True):\n",
        "    \"\"\" \n",
        "    This function transforms a dataframe in a timeseries for surpervised learning.\n",
        "        timesteps: Number of delays (i.e: timesteps =2 (t),(t-1),(t-2));\n",
        "        df: Dataframe;\n",
        "        predictors: List of columns in dataframe as features for the ML algorithm;\n",
        "        target: Target of the supervised learning;\n",
        "        dropnan: Flag to drop the NaN values after transforming the \n",
        "        out: Number of steps to forecast (i.e: out = 2 (t),(t+1));\n",
        "        dropVars= Leave only the Target of the last timestep on the resulting dataframe;\n",
        "    \"\"\"    \n",
        "    \n",
        "    series = series_to_supervised(df[predictors+[target]].copy(),timesteps,out,dropnan=dropnan)\n",
        " \n",
        "    if dropnan==False:\n",
        "        series.replace(pd.np.nan,0,inplace=True)\n",
        "    \n",
        "    # Dropping other variables:\n",
        "    if dropVars:\n",
        "        index = list(np.arange(series.shape[1]-2,\n",
        "                               series.shape[1]-len(predictors)-2,\n",
        "                               -1))\n",
        " \n",
        "        labels = [item  for idx,item in enumerate(series.columns) \n",
        "                  if idx in index]\n",
        " \n",
        "        #print(\"Eliminando variáveis: {}\".format(labels))\n",
        "        series.drop(labels,axis=1,inplace=True)  \n",
        " \n",
        "    return series\n",
        "\n",
        "class Cross_valid_clf():\n",
        "  \"\"\" \n",
        "    This class does cross validation for general classifiers. \n",
        "        model: Sklearn model or customized model with fit and predict methods;\n",
        "        X: array with values for features\n",
        "        y:array with values for target\n",
        "        folds: Number of folds;\n",
        "        metrics : accuracy,f1score, precision,recall,fbeta score;\n",
        "        stratified: Use stratified Kfold to keep the ratio of classes in all folds;\n",
        "        beta: Beta parameter for fbeta score metric;\n",
        "        verbose: Flag to print report over iterations;\n",
        "        \n",
        "    returns: List with scores over the folders\n",
        "  \"\"\"            \n",
        "  def __init__(self, X, y,n_splits,stratified=True):\n",
        "    self.n_splits = n_splits\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "        \n",
        "    if stratified:\n",
        "        self.kf=StratifiedKFold(self.n_splits,shuffle=False,random_state=0)\n",
        "        self.kf.get_n_splits(self.X)\n",
        "    else:\n",
        "        self.kf=KFold(self.n_splits,shuffle=False,random_state=0)\n",
        "        self.kf.get_n_splits(self.X)\n",
        "\n",
        "  #score method\n",
        "  def score(self, clf,verbose=True):\n",
        "        score = []\n",
        "        i=0\n",
        "        for tr, te in self.kf.split(self.X,self.y):\n",
        "            clf.fit(self.X[tr],self.y[tr])\n",
        "            score.append(clf.score(self.X[te],self.y[te]))\n",
        "            if verbose:\n",
        "                print('-'*30)\n",
        "                print(f'\\nFold {i+1} out of {self.n_splits}')\n",
        "                print(f'Accuracy_score: {score[i]}')\n",
        "            i+=1\n",
        "        if verbose:\n",
        "            print(f'\\n Overall Score:')\n",
        "            print(f'Accuracy_score Mean: {np.mean(score)}   Std: {np.std(score)}')\n",
        "        return np.mean(score)\n",
        "    #f1score method\n",
        "  def f1score(self, clf,verbose=True):\n",
        "        f1score = []\n",
        "        i=0\n",
        "        for tr, te in self.kf.split(self.X,self.y):\n",
        "            clf.fit(self.X[tr],self.y[tr])\n",
        "            y_pred=clf.predict(self.X[te])\n",
        "            f1score.append(f1_score(y_pred,self.y[te]))\n",
        "            if verbose:\n",
        "                print('-'*30)\n",
        "                print(f'\\nFold {i+1} out of {self.n_splits}')\n",
        "                print(f'f1_score: {f1score[i]}')\n",
        "            i+=1\n",
        "        if verbose:\n",
        "            print(f'\\n Overall f1score:')\n",
        "            print(f'f1score Mean: {np.mean(f1score)}   Std: {np.std(f1score)}')\n",
        "        return np.mean(f1score)\n",
        "    #precision score\n",
        "  def precisionscore(self, clf,verbose=True):\n",
        "        prec_score = []\n",
        "        i=0\n",
        "        for tr, te in self.kf.split(self.X,self.y):\n",
        "            clf.fit(self.X[tr],self.y[tr])\n",
        "            y_pred=clf.predict(self.X[te])\n",
        "            prec_score.append(precision_score(y_pred,self.y[te]))\n",
        "            if verbose:\n",
        "                print('-'*30)\n",
        "                print(f'\\nFold {i+1} out of {self.n_splits}')\n",
        "                print(f'Precision_score: {prec_score[i]}')\n",
        "            i+=1\n",
        "        if verbose:\n",
        "            print(f'\\n Overall Score:')\n",
        "            print(f'Precision_score Mean: {np.mean(prec_score)}   Std: {np.std(prec_score)}')\n",
        "        return np.mean(prec_score)\n",
        "    #Recall score      \n",
        "  def recallscore(self, clf,verbose=True):\n",
        "        rec_score = []\n",
        "        i=0\n",
        "        for tr, te in self.kf.split(self.X,self.y):\n",
        "            clf.fit(self.X[tr],self.y[tr])\n",
        "            y_pred=clf.predict(y_pred,self.X[te])\n",
        "            rec_score.append(recall_score(self.X[te],self.y[te]))\n",
        "            if verbose:\n",
        "                print('-'*30)\n",
        "                print(f'\\nFold {i+1} out of {self.n_splits}')\n",
        "                print(f'Recall_score: {rec_score[i]}')\n",
        "            i+=1\n",
        "        if verbose:\n",
        "            print(f'\\n Overall Score:')\n",
        "            print(f'Recall_score Mean: {np.mean(rec_score)}   Std: {np.std(rec_score)}')\n",
        "        return np.mean(rec_score)\n",
        "    #fbeta score\n",
        "  def fbetascore(self, clf,verbose=True,beta=0.6):\n",
        "        fbetascore = []\n",
        "        i=0\n",
        "        for tr, te in self.kf.split(self.X,self.y):\n",
        "            clf.fit(self.X[tr],self.y[tr])\n",
        "            y_pred=clf.predict(self.X[te])\n",
        "            fbetascore.append(fbeta_score(y_pred,self.y[te],beta))\n",
        "            if verbose:\n",
        "                print('-'*30)\n",
        "                print(f'\\nFold {i+1} out of {self.n_splits}')\n",
        "                print(f'fbeta_score: {fbetascore[i]}')\n",
        "            i+=1\n",
        "        if verbose:\n",
        "            print(f'\\n Overall Score:')\n",
        "            print(f'fbeta_score Mean: {np.mean(fbetascore)}   Std: {np.std(fbetascore)}')\n",
        "        return np.mean(fbetascore)\n",
        "\n",
        "class Cross_valid_reg():\n",
        "  \"\"\" \n",
        "    This class does cross validation for general regressors. \n",
        "        model: Sklearn model or customized model with fit and predict methods;\n",
        "        x : features;\n",
        "        y: target\n",
        "        folds: Number of folds;\n",
        "        metrics : RMSE =root mean squared error; MAE= mean absolute error\n",
        "        stratified: Use stratified Kfold to keep the ratio of classes in all folds;\n",
        "        verbose: Flag to print report over iterations;\n",
        "        \n",
        "    returns: List with scores over the folders\n",
        "  \"\"\"    \n",
        "  def __init__(self, X, y,n_splits,stratified=True):\n",
        "    self.n_splits = n_splits\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "        \n",
        "    if stratified:\n",
        "        self.kf=StratifiedKFold(self.n_splits,shuffle=False,random_state=0)\n",
        "        self.kf.get_n_splits(self.X)\n",
        "    else:\n",
        "        self.kf=KFold(self.n_splits,shuffle=False,random_state=0)\n",
        "        self.kf.get_n_splits(self.X)\n",
        "\n",
        "  #score method\n",
        "  def rmse(self, reg,verbose=True,overall=True):\n",
        "    #rmse\n",
        "        rmse = []\n",
        "        i=0\n",
        "        for tr, te in self.kf.split(self.X,self.y):\n",
        "            reg.fit(self.X[tr],self.y[tr])\n",
        "            y_pred=reg.predict(self.X[te])\n",
        "            rmse.append(np.sqrt(mean_squared_error(y_pred,self.y[te])))\n",
        "            if verbose:\n",
        "                print('-'*30)\n",
        "                print(f'\\nFold {i+1} out of {self.n_splits}')\n",
        "                print(f'RMSE: {rmse[i]}')\n",
        "            i+=1\n",
        "        if verbose:\n",
        "            print(f'\\n Overall RMSE:')\n",
        "            print(f'RMSE Mean: {np.mean(rmse)}   Std: {np.std(rmse)}')\n",
        "        if overall:\n",
        "            return np.mean(rmse)\n",
        "        else:\n",
        "            return rmse\n",
        "    #mae\n",
        "  def mae(self, reg,verbose=True,overall=True):\n",
        "        mae = []\n",
        "        i=0\n",
        "        for tr, te in self.kf.split(self.X,self.y):\n",
        "            reg.fit(self.X[tr],self.y[tr])\n",
        "            y_pred=reg.predict(self.X[te])\n",
        "            mae.append(mean_absolute_error(y_pred,self.y[te]))\n",
        "            if verbose:\n",
        "                print('-'*30)\n",
        "                print(f'\\nFold {i+1} out of {self.n_splits}')\n",
        "                print(f'MAE: {mae[i]}')\n",
        "            i+=1\n",
        "        if verbose:\n",
        "            print(f'\\n Overall MAE:')\n",
        "            print(f'MAE Mean: {np.mean(mae)}   Std: {np.std(mae)}')\n",
        "        if overall:\n",
        "            return np.mean(mae)\n",
        "        else:\n",
        "            return mae\n",
        "  def r2(self, reg,verbose=True,overall=True):\n",
        "        r2 = []\n",
        "        i=0\n",
        "        for tr, te in self.kf.split(self.X,self.y):\n",
        "            reg.fit(self.X[tr],self.y[tr])\n",
        "            y_pred=reg.predict(self.X[te])\n",
        "            mae.append(r2_score(y_pred,self.y[te]))\n",
        "            if verbose:\n",
        "                print('-'*30)\n",
        "                print(f'\\nFold {i+1} out of {self.n_splits}')\n",
        "                print(f'R2: {r2[i]}')\n",
        "            i+=1\n",
        "        if verbose:\n",
        "            print(f'\\n Overall R2:')\n",
        "            print(f'R2 Mean: {np.mean(r2)}   Std: {np.std(r2)}')\n",
        "        if overall:\n",
        "            return np.mean(r2)\n",
        "        else:\n",
        "            return r2  \n",
        "    #precision score\n",
        "\n",
        "def feature_importance_plot(algorithm,X_train,y_train,of_type):\n",
        "    \"\"\"This function does the feature importance for any classifiers or regressors.\n",
        "    Parameters\n",
        "    ----------------\n",
        "    algorithm: Algorithm which one wants to importance the relevant features\n",
        "    X_train: axis x of the train dataframe\n",
        "    y_train: axis y of the target dataframe\n",
        "    of_type: 'coef' or 'feat', depending on the algorithm.\n",
        "    Return\n",
        "    -----------------\n",
        "    Plot with feature importances\n",
        "    \"\"\"\n",
        "    if of_type == \"coef\":\n",
        "        algorithm.fit(X_train,y_train)\n",
        "        coef = pd.DataFrame(algorithm.coef_.ravel())\n",
        "        coef[\"coef\"] = X_train.columns\n",
        "        plt.figure(figsize=(14,4))\n",
        "        ax1 = sns.barplot(coef[\"coef\"],coef[0],palette=\"jet_r\",\n",
        "                          linewidth=2,edgecolor=\"k\"*coef[\"coef\"].nunique())\n",
        "        #ax1.set_facecolor(\"lightgrey\")\n",
        "        ax1.axhline(0,color=\"k\",linewidth=2)\n",
        "        plt.ylabel(\"coefficients\")\n",
        "        plt.xlabel(\"features\")\n",
        "        plt.xticks(rotation='vertical')\n",
        "        plt.title('FEATURE IMPORTANCES')\n",
        "    \n",
        "    elif of_type == \"feat\":\n",
        "        algorithm.fit(X_train,y_train)\n",
        "        coef = pd.DataFrame(algorithm.feature_importances_)\n",
        "        coef[\"feat\"] = X_train.columns\n",
        "        plt.figure(figsize=(14,4))\n",
        "        ax2 = sns.barplot(coef[\"feat\"],coef[0],palette=\"jet_r\",\n",
        "                          linewidth=2,edgecolor=\"k\"*coef[\"feat\"].nunique())\n",
        "        #ax2.set_facecolor(\"lightgrey\")\n",
        "        ax2.axhline(0,color=\"k\",linewidth=2)\n",
        "        plt.ylabel(\"coefficients\")\n",
        "        plt.xlabel(\"features\")\n",
        "        plt.xticks(rotation='vertical')\n",
        "        plt.title('FEATURE IMPORTANCES')\n",
        "def algorithm_grid_search_cv(X_train_data, X_test_data, y_train_data, y_test_data, \n",
        "                       model, param_grid, cv=10, scoring_fit='neg_mean_squared_error',\n",
        "                       do_probabilities = False):\n",
        "    gs = GridSearchCV(\n",
        "        estimator=model,\n",
        "        param_grid=param_grid, \n",
        "        cv=cv, \n",
        "        n_jobs=-1, \n",
        "        scoring=scoring_fit,\n",
        "        verbose=2\n",
        "    )\n",
        "    fitted_model = gs.fit(X_train_data, y_train_data)\n",
        "    \n",
        "    if do_probabilities:\n",
        "      pred = fitted_model.predict_proba(X_test_data)\n",
        "    else:\n",
        "      pred = fitted_model.predict(X_test_data)\n",
        "    \n",
        "    return fitted_model, pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtKV0QJfkjqs",
        "colab_type": "text"
      },
      "source": [
        "# Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixTOIGznhozN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a8c1b4db-23b1-4947-ca7e-6b817a4c575a"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>balance</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>58</td>\n",
              "      <td>management</td>\n",
              "      <td>married</td>\n",
              "      <td>tertiary</td>\n",
              "      <td>no</td>\n",
              "      <td>2143</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>261</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44</td>\n",
              "      <td>technician</td>\n",
              "      <td>single</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>29</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>151</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33</td>\n",
              "      <td>entrepreneur</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>76</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>47</td>\n",
              "      <td>blue-collar</td>\n",
              "      <td>married</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>1506</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>92</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33</td>\n",
              "      <td>unknown</td>\n",
              "      <td>single</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>198</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age           job  marital  education  ... pdays  previous poutcome   y\n",
              "0   58    management  married   tertiary  ...    -1         0  unknown  no\n",
              "1   44    technician   single  secondary  ...    -1         0  unknown  no\n",
              "2   33  entrepreneur  married  secondary  ...    -1         0  unknown  no\n",
              "3   47   blue-collar  married    unknown  ...    -1         0  unknown  no\n",
              "4   33       unknown   single    unknown  ...    -1         0  unknown  no\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Get_Ordnjr9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}